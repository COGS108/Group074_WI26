{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a74aa045",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a24747c",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad624e6e",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Arjun Yadalla: ...\n",
    "- Aditya Mittal: Scraped and wrangled salary data, Modified Timeline\n",
    "- Sal Martinez: ...\n",
    "- Sri Gentela: ...\n",
    "- Thaarak Sriram: Wrote the paragraph write-ups for the Player Totals Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dbcf05b",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0bea1e0",
   "metadata": {},
   "source": [
    "To what extent can NBA player salaries over the past five seasons be predicted by on-court performance metrics, and how closely do current player salaries align with statistically measured contributions to team success?\n",
    "\n",
    "Prior research has shown that machine learning models can predict NBA player salaries with relatively high accuracy, often achieving strong explanatory power using performance statistics. However, these studies also emphasize important limitations, particularly the influence of structural factors such as rookie-scale contracts, maximum salary rules, and salary cap growth, which can weaken the alignment between statistical performance and compensation. Although earlier work reports strong predictive results, there has been less examination of how well modern NBA salaries reflect measured player contributions, especially in the context of recent salary cap expansion and evolving team valuation strategies. By focusing on the most recent five-year period, this study builds upon prior findings and investigates whether differences between predicted and actual salaries reveal systematic patterns in how players are compensated relative to their on-court impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e034a8",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efc6332c",
   "metadata": {},
   "source": [
    "Basketball is one of the most popular and widely played sports in the world, with the National Basketball Association (NBA) leading global viewership in professional basketball. The league serves as the premier stage where elite athletes compete annually for the championship title. In recent years, NBA player salaries have skyrocketed, with compensation determined by a complex interplay of factors including individual performance statistics, team success, market dynamics, roster needs, and league-imposed salary cap regulations. For team management, understanding the relationship between a player's on-court contributions and their salary compensation is critically important—the ability to construct an effective roster within salary cap constraints often determines whether a franchise competes for championships or remains mediocre. This project seeks to leverage machine learning techniques to predict NBA player salaries based on statistical performance over the last five years, focusing specifically on quantifying how much players contribute to their teams relative to their compensation.\n",
    "\n",
    "Multiple research studies have applied machine learning techniques to predict NBA player salaries with considerable success. An analysis using Random Forest and Gradient Boosting models found that minutes per game, points scored, and previous season salary were the most impactful features in predicting player compensation, with models achieving R² values around 0.85-0.90.[<sup>1</sup>](#cite_note-1) Interestingly, this research noted that advanced statistics like Value Over Replacement Player (VORP) and Win Shares were not as dominant in salary predictions as more basic counting metrics like points and games started. Additional research enhanced by optimization algorithms achieved even higher accuracy, with R² values reaching 0.987 during training phases, demonstrating the potential for sophisticated machine learning approaches to capture salary determination patterns.[<sup>2</sup>](#cite_note-2)\n",
    "\n",
    "However, these studies also reveal important challenges and limitations in salary prediction models. Research has shown that factors beyond statistical performance significantly influence player compensation, including market size, player marketability, injury history, and contract structure constraints such as rookie scale contracts and maximum salary rules.[<sup>3</sup>](#cite_note-3) This suggests that models relying purely on performance statistics face inherent limitations when accounting for the realities of contract negotiations. Furthermore, analysis of how teams value different statistics in contract negotiations found that organizations tend to overvalue traditional counting stats like points and blocks while undervaluing efficiency metrics such as effective field goal percentage (eFG%) and Win Shares when determining salaries.[<sup>4</sup>](#cite_note-4) This disconnect between statistical value and market value presents both a challenge for prediction models and an opportunity for teams seeking competitive advantages.\n",
    "\n",
    "While machine learning models have demonstrated strong predictive performance with typical Mean Absolute Errors around $3-5 million on test datasets, significant prediction errors often occur for specific player categories.[<sup>5</sup>](#cite_note-5) Rookie contract players, whose salaries are predetermined by draft position regardless of performance, and superstar players on maximum contracts, whose compensation is capped by collective bargaining agreement rules regardless of statistical dominance, present particular challenges for purely statistics-based models. Additionally, the NBA's rapid salary cap increases necessitate that researchers predict salary as a percentage of total cap space rather than absolute dollar amounts to account for temporal factors.\n",
    "\n",
    "This project will build upon existing work by analyzing statistical data from the last five seasons, a period characterized by considerable salary cap growth and evolving team strategies. It aims to develop models that identify relationships between comprehensive player performance metrics and compensation while acknowledging the structural constraints that limit purely statistics-based predictions.\n",
    "\n",
    "---\n",
    "\n",
    "**References**\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Towards Data Science. (2025). Predicting NBA Salaries with Machine Learning. https://towardsdatascience.com/predicting-nba-salaries-with-machine-learning-ed68b6f75566/\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Cheng, Y., Song, Y., & Wang, M. (2025). Leveraging Machine Learning for Accurate Prediction of NBA Player Salaries. *Iraqi Journal for Computer Science and Mathematics*, Vol. 6, Iss. 3. https://ijcsm.researchcommons.org/ijcsm/vol6/iss3/1/\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) NHS Journal of Science. (2025). Computational Analysis of NBA Players with Machine and Deep Learning. https://nhsjs.com/2025/computational-analysis-of-nba-players-with-machine-and-deep-learning/\n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Harvard Sports Analysis Collective. (2023). MoneyB-ball: An Analysis of Over and Undervalued NBA Statistics. https://harvardsportsanalysis.org/2023/05/moneyb-ball-an-analysis-of-over-and-undervalued-nba-statistics/\n",
    "5. <a name=\"cite_note-5\"></a> [^](#cite_ref-5) Carr, E. (2025). Predicting NBA Contracts Using Statistics. *Medium - INST414: Data Science Techniques*. https://medium.com/inst414-data-science-tech/predicting-nba-contracts-using-statistics-8842f3bd45e3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ea18512",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c67d0ca",
   "metadata": {},
   "source": [
    "We hypothesize that NBA player salaries over the past 5 seasons can be predicted with relatively high accuracy using machine learning models trained on on-court performance metrics, but that prediction accuracy will be constrained by non-performance factors embedded in the NBA’s contract system. \n",
    "\n",
    "We further hypothesize that traditional performance statistics, such as minutes played, points per game, and games started, will be stronger predictors of salary than advanced efficiency metrics like Win Shares and Box Plus/Minus. This expectation aligns with prior research indicating that teams tend to prioritize more visible and easily interpretable statistics during contract negotiations.\n",
    "\n",
    "Finally, we hypothesize that discrepancies between predicted and actual salaries will be most pronounced for players on rookie-scale contracts and maximum contracts, where league rules cap compensation independently of on-court statistical performance. These discrepancies will indicate that salary alignment with measured contribution is imperfect, even when strong predictive models are used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30756c0f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4403d2a4",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Players Total Dataset\n",
    "  - Dataset Name: player_totals.csv\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/sumitrodatta/nba-aba-baa-stats/data?select=Player+Totals.csv\n",
    "  - Number of observations:33,140\n",
    "  - Number of variables: 33\n",
    "  - Description of the variables most relevant to this project:\n",
    "    - mp: Total minutes played\n",
    "    - fg, fga: Field goals made and attempted (season totals)\n",
    "    - x3p, x3pa: 3-pointers made and attempted\n",
    "    - ft, fta: Free throws made and attempted\n",
    "    - orb, drb, trb: Offensive, defensive, and total rebounds\n",
    "    - ast: Total assists\n",
    "    - stl: Total steals\n",
    "    - blk: Total blocks\n",
    "    - tov: Total turnovers\n",
    "    - pf: Total personal fouls\n",
    "    - pts: Total points scored\n",
    "    - trp_dbl: Triple-doubles achieved\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project:\n",
    "    - Players who played for multiple teams in one season have separate rows (need aggregation for season totals)\n",
    "    - Triple-double data may be incomplete for historical seasons\n",
    "    - No efficiency or rate statistics (raw totals only)\n",
    "    - Doesn't account for pace of play differences across eras\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ae0f2",
   "metadata": {},
   "source": [
    "### NBA Player Season Totals: Comprehensive Basketball Performance Statistics (1947-2026)\n",
    "#### Data Overview\n",
    "This smaller section of the dataset contains 4,200 player-season observations from 2021-2026, with 3,962 remaining after removing players with minimal playing time (<20 minutes). Key statistics include points (pts) measuring total scoring output, where median players score 280 points per season, rotation players (75th percentile) score 636 points, and elite scorers (90th percentile) exceed 1,049 points. Field goal percentage (fg_percent) measures shooting efficiency, with typical values at 45%, starters at 50%, and elite finishers at 60%+, while three-point percentage (x3p_percent) averages 35% with elite shooters exceeding 43%. Rebounds (trb) count possessions gained after missed shots (median 120, elite 371+), assists (ast) measure scoring passes created (median 58, elite 255+), and steals/blocks measure defensive plays (median 23 steals, 11 blocks). Games played (g) indicates participation (median 40 of 82 maximum games) and minutes (mp) measures playing time (median 741 minutes, starters 2,054+ minutes).\n",
    "\n",
    "#### Data: Limitations and Potential Biases\n",
    "The dataset includes 12.7% of player-seasons with multi-team entries where traded players have separate rows for each team, requiring some data manipulation to avoid double-counting. There’s also no information about injuries, player roles, competition quality, or trade circumstances, making it impossible to distinguish whether poor statistics reflect declining ability, injury, reduced opportunity, or situational factors. This means the dataset captures what happened statistically but not why, limiting interpretation beyond surface-level comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c495e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1dee1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfa426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://drive.google.com/uc?export=download&id=1ve2Lev0GSyFqkxsbprIa56BNz2au4TBM', 'filename':'Player+Totals.csv'},\n",
    "    { 'url': 'https://drive.google.com/uc?export=download&id=1c23RZNGQyN0s3C61H5-d_NWQbfsdKfzL', 'filename':'salary_data_raw.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879cc825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/data/00-raw/Player+Totals.csv')\n",
    "#A: Reads stats and assigsn it to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7965dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"season\"] >= 2021].copy()\n",
    "\n",
    "df.shape\n",
    "#C: Says how many rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "#Gives us the names of the columns to see what we should change and how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de61ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = df.isna().sum().sort_values(ascending=False)\n",
    "missing_percent = (df.isna().mean()*100).sort_values(ascending=False)\n",
    "missing_counts,missing_percent\n",
    "# D: Checking for missing data\n",
    "# Counts how many missing values are in each column and calculates the percentage of missing values\n",
    "# Allows us to see where data is missing and how much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"ft_percent\"].isna()].head()\n",
    "# D: Inspecting missing entries\n",
    "# Show the first couple of rows where 'ft_percent' is missing to check for patterns or any larger problem like a year missing stat or certain player or team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddb73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_cols = [\n",
    "    \"fg_percent\",\n",
    "    \"x3p_percent\",\n",
    "    \"x2p_percent\",\n",
    "    \"ft_percent\",\n",
    "    \"e_fg_percent\"\n",
    "]\n",
    "\n",
    "df[percent_cols] = df[percent_cols].fillna(0)\n",
    "# F: Handles the missing data\n",
    "# Replaces the missing data with a 0 because we are assuming that missing just means they did not attempt it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc04d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"trp_dbl\"] = df[\"trp_dbl\"].fillna(0)\n",
    "#F: Doing the same thing but with triple doubles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()\n",
    "# F: Makes sure the data is cleansed\n",
    "# Check that all missing values have been replaced with zero this line will print 0 if done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a192b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"e_fg_percent\"] > 1) | (df[\"e_fg_percent\"] < 0)]\n",
    "# E: Finding any data that is suspicious or impossible\n",
    "# Identifies rows which are not in the fair range of 0-1 impossible to shoot 120% in a game\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4840d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"e_fg_percent\"] > 1) | (df[\"e_fg_percent\"] < 0), \"e_fg_percent\"] = np.nan\n",
    "df[\"e_fg_percent\"] = df[\"e_fg_percent\"].fillna(0)\n",
    "# E and F: Takes those suspicious values and replaces them with missing \n",
    "# Then this is the F part replaces missing with zero again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()\n",
    "#F: is making sure our data is clean again by adding all instances of missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "#Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44007edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_team = df[df[\"team\"].str.contains(\"TM\")]\n",
    "\n",
    "players_with_total = multi_team[[\"player\",\"season\"]]\n",
    "\n",
    "df_clean = df.merge(players_with_total, on=[\"player\",\"season\"], how=\"left\", indicator=True)\n",
    "\n",
    "df_clean = df_clean[\n",
    "    ~((df_clean[\"_merge\"] == \"both\") & (~df_clean[\"team\"].str.contains(\"TM\")))\n",
    "]\n",
    "\n",
    "df_clean = df_clean.drop(columns=\"_merge\")\n",
    "\n",
    "#Cleaning to remove people who played on two teams in a single season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49d2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[df_clean['player']=='Anthony Davis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16ce38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08c92b02",
   "metadata": {},
   "source": [
    "### NBA Salary Dataset 2018-2026\n",
    "\n",
    "#### Dataset Overview: \n",
    "This dataset contains salary information for National Basketball Association (NBA) players across multiple seasons spanning from 2018-19 through 2025-26. The data captures player compensation as determined by official NBA contracts for each respective season. Each observation in the cleaned dataset represents a single player’s salary for a specific season, meaning that one player may appear multiple times across different seasons. \n",
    "\n",
    "The dataset was originally structured in a wide format, with each season represented as a separate column. For analysis purposes, the data was reshaped into a tidy long format so that each row corresponds to one player-season combination. This structure allows for more effective statistical analysis, visualization, and modeling of salary trends over time.\n",
    "\n",
    "The scope of the dataset is limited to NBA players with recorded contracts during the listed seasons. It does not include endorsement income or compensation outside of official NBA contracts.\n",
    "\n",
    "#### Variables & Units: \n",
    "This dataset contains three primary variables following the restructuring process:\n",
    "\n",
    "- name\n",
    "\n",
    "This variable identifies the NBA player. It is categorical and serves as a unique identifier when paired with a season. A single player may appear multiple times in the dataset if they played across multiple seasons. If players have contracts that extend into the upcoming years, they are included. \n",
    "- team\n",
    "\n",
    "This variable indicates the NBA team the player was contracted with during that season. It is categorical. If a player was traded mid-season, they may appear multiple times in the same season with different teams, depending on how trades are recorded in the dataset.\n",
    "- season\n",
    "\n",
    "This variable represents the NBA season in which the salary was earned. Seasons are formatted as YYYY–YY (e.g., 2023–24). This is a categorical time variable indicating the league year rather than a calendar year.\n",
    "- salary\n",
    "\n",
    "This variable represents a player’s contracted salary for a given season. Salary is measured in U.S. dollars (USD) and reflects official NBA contract compensation for that season. The values are numeric and allow for quantitative analysis of salary distribution, trends over time, and comparisons across players.\n",
    "\n",
    "It is important to note that salary values reflect contract-based earnings only. They do not include endorsement deals, sponsorships, or other off-court income. As a result, the dataset captures official league compensation rather than total player earnings.\n",
    "\n",
    "- two_way\n",
    "\n",
    "This is a binary variable indicating whether a player was on a two-way contract during that season. Two-way contracts allow players to split time between an NBA team and its G-League affiliate. This variable typically takes values such as True/False or 1/0. Two-way players generally earn lower salaries than standard NBA contract players.\n",
    "\n",
    "#### Interpretation of Key Metrics:\n",
    "The primary quantitative variable in this dataset is salary, measured in U.S. dollars. NBA salaries vary substantially due to differences in experience, performance level, contract type, and league salary cap rules. As a result, the distribution of salaries is highly right-skewed.\n",
    "\n",
    "At the lower end of the distribution, players on rookie contracts, minimum contracts, or two-way contracts typically earn between approximately $500,000 and $2 million per season. Two-way contract players generally earn less than players on standard NBA contracts because they split time between the NBA and the G-League.\n",
    "\n",
    "Mid-level contracts commonly range from $5 million to $20 million per season. These contracts often reflect established role players or strong starters. At the upper end of the distribution, maximum and “supermax” contracts can exceed $40–50 million per season. These high values are typically associated with All-Star or franchise-level players.\n",
    "\n",
    "Because a small number of players earn extremely large salaries relative to the rest of the league, the mean salary may be significantly higher than the median salary. For this reason, median salary can sometimes provide a better representation of a “typical” NBA player’s earnings. The salary structure is also influenced by NBA collective bargaining agreements and the league’s salary cap, which limits total team payroll and shapes contract values.\n",
    "\n",
    "#### Dataset Structure & Tidy Status:\n",
    "The dataset was originally structured in a wide format, where each season appeared as a separate column and many cells were empty. In this format, a player’s salary history was spread across multiple columns, making analysis less efficient and not aligned with tidy data principles.\n",
    "\n",
    "The dataset was reshaped into a long (tidy) format so that each row represents one player-season observation, with separate columns for name, season, team, two-way status, and salary. In the cleaned version, each row corresponds to a single observational unit, and each column represents one variable. This structure supports clearer analysis, grouping, and modeling.\n",
    "\n",
    "#### Missing Data:\n",
    "In the original wide-format dataset, a large number of cells were missing because each player typically had salary information recorded for only certain seasons. As a result, most rows contained many empty values across seasonal columns. This missingness was structural rather than random, meaning it resulted from the dataset’s format rather than incomplete or erroneous data collection.\n",
    "\n",
    "After reshaping the dataset into tidy long format, rows with missing salary values were removed. Because salary is the primary variable of interest, observations without a recorded salary were excluded from the final cleaned dataset. Following this transformation, missingness was minimal and did not appear to follow any systematic pattern.\n",
    "\n",
    "#### Data Limitations and Potential Biases:\n",
    "While this dataset provides structured information about NBA player salaries, several limitations should be considered. First, the dataset includes only players with official NBA contracts during the listed seasons. It does not include G-League players, international players, or individuals outside the NBA, meaning the data is not representative of all professional basketball players.\n",
    "\n",
    "Second, salary values reflect contract-based NBA compensation only. The dataset does not account for endorsement deals, sponsorship income, performance bonuses (unless guaranteed within the contract), or other off-court earnings. As a result, the salary variable represents official league compensation rather than total player income.\n",
    "\n",
    "Additionally, players who were traded mid-season may appear multiple times within the same season under different teams. Until trade adjustments are finalized, this could inflate the number of observations per season and slightly distort team-level analysis.\n",
    "\n",
    "Finally, salary values are not adjusted for inflation or changes in the NBA salary cap over time. Because the league’s revenue and salary cap have increased across seasons, direct comparisons of salaries across different years should be interpreted with this context in mind.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feac63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "salary_df_raw = pd.read_csv(\"data/00-raw/salary_data_raw.csv\")\n",
    "salary_df_current = salary_df_raw.drop([\"2026-27\", \"2027-28\",\"2028-29\"], axis = 1)\n",
    "\n",
    "salary_df = pd.melt(salary_df_current, id_vars=['name', 'team'], var_name='Season', value_name='Salary').dropna()\n",
    "\n",
    "salary_df =salary_df.assign(Two_Way = salary_df.Salary.apply(lambda sal: sal[0:2] == \"TW\"))\n",
    "salary_df = salary_df.assign(Salary = salary_df.Salary.apply(lambda sal: int(''.join([c for c in sal if c.isnumeric()]))))\n",
    "salary_df.to_csv(\"data/02-processed/salary_data.csv\")\n",
    "salary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df[salary_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92fb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(salary_df, x = \"Salary\", log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc8b95",
   "metadata": {},
   "source": [
    "### Combining Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb9dc4-ee95-4170-90dc-7d198575d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0e6e346",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b0f40e1",
   "metadata": {},
   "source": [
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "> As far as the data that we use it will most likely stay in our resumes and the data will become outdated in less than a year so it will be deleted then. \n",
    "\n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "> Yes the process of documenting will be simple and follow clear steps and guidelines as well as the reasoning behind it. \n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "> There is a natural statistical bias towards players on great teams. Such as a defensive team having inflated defensive ratings as if they let a man through the next guy might stop him. Same for offense, lots of good shooters have more shots and more assist. \n",
    " - [X] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "> Fairness across groups is difficult since situations matter a lot as talked about with better defensive teams better rating. Same with offense as well as coaching however our algorithm can only take in the numbers we can adjust if a certain team is statistically overperforming or at least not this anomaly. \n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    " - [X] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    "> Yes, the statistics we use are self explanatory and if human judgement is necessary things defensive quality and judging their situation could come into account though most likely this will not be needed at all. \n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "> We do have a plan to monitor the model on how it does simply by comparing the contracts that the players are getting and what we predicted. As well as how good the team performance is with the changes in mind and if the model was correct.\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9392152",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1cdfc68",
   "metadata": {},
   "source": [
    "* Clear Roles/Responsibilities\n",
    "  * Every team member will take responsibility for different components of the project. Responsibilities include data collection and cleaning, modeling and analysis, and report writing. While all responsibilities will be divided, all members of the team are expected to understand the full project and are able to provide feedback to their teammates as well as ask for help when needed. \n",
    "* Communication/Availability\n",
    "  * The team must regularly and properly communicate through messages and meet at least once a week, on a date TBD. At this meeting, we will discuss current progress, address challenges that we are facing, plan the next steps of the project, and work on the project and get help. Team members are expected to respond to messages in a timely manner and notify the group if any conflicts arise. \n",
    "* Accountability/Deadlines\n",
    "  * Deadlines will be set ahead of course deadlines to allow time for review and revisions amongst the team. Team members are expected to complete their assigned tasks on time and inform the group ahead of time if they need extra assistance. \n",
    "* Collaboration & Respect\n",
    "  * All team members are expected to contribute respectfully, listen to differing opinions, and engage constructively in discussions. They shouldn’t be distracted by other tasks and instead give their full, undivided attention to the group. Decisions regarding the project will be made collaboratively. \n",
    "* Quality & Academic Integrity\n",
    "  * The team is committed to producing high-quality, reproducible work. All code will be documented and shared through version control, and all sources will be properly cited. Any use of external tools or assistance will comply with course policies. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3a154f5",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f731823",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/28  |  12:30 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; Begin background research | \n",
    "| 2/5  |  12:30 PM |  Submit project proposal; understand hypothesis; get datasets and variables | Collect NBA performance and salary datasets; Assign specific roles | \n",
    "| 2/12   | 12:30 PM  | Look through data; Begin basic data analysis  | Discuss Analysis Plan; Assign Roles for Data Checkpoint  |\n",
    "| 2/18  | 12:30 PM  | Align player and season data; Wrangle/Clean Data; Complete Data Checkpoint; Impute Data  | Submit Data Checkpoint; Encode Categorical Data|\n",
    "| 2/26  | 12:30 PM  | Build baseline salary prediction models; Analyze Features | Review model results; Decide on Final Features; Assign Roles for EDA Checkpoint |\n",
    "| 3/4  | 12:30 PM  | Submit EDA Checkpoint; Create visualizations; Train machine learning models (RandomForestRegressor, XGBoost)  | Start drafting Final Project; Assign Roles for Final Project|\n",
    "| 3/12  | 12:30 PM  | Review model results; Complete assigned final project parts; Format notebook | Review final project notebook; Create video|\n",
    "| 3/18  | 11 PM  | Final edits & polish final submission | Turn in Final Project & Group Project Surveys|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
